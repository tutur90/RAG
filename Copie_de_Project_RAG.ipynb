{"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/tutur90/RAG/blob/main/Copie_de_Project_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"eLtiBx5FOWer"},"source":["# Project : RAG\n","\n","The goal of this project is to create a simple LLMs based RAG module. Obviously the most complex part is how to correctly link all components. We let you free to create your own database. Anything can be ragged, from research paper, songs, subtitles, books,...\n","\n","This project is voluntarly sparsely helped, as, as engineers, you will dig into lots of existing method, and will need to pick the best one up. We want you to get familiar with the engineering world.\n","\n","We will give you some recommendations. You will see lots of issues during this project, some you've already seen during Labs, other that are new. So buckle up, read the docs, and RAG your data.\n","\n","Obviously there are lots of tutorials of the internet that you could just copy paste to get a baseline.\n","\n","\n","## **We encourage you to do code versioning using Github.**\n","\n","\n","**Ideal Project Timeline:**\n","\n","*   Talking and getting to know the Modules. Discussing about the choice of your LLMs and the environment you'll have. Choosing a first set of data to RAG. Setting up your Github (Optional) (1h)\n","*   Setting up your first RAG Chain using Langchain or other (2-3h)\n","*   Understand the limitation of your RAG and find enhancements to set up your 2nd RAG. (2h)\n","*   Unveiling the unknown document, adapt your RAGs (2h)\n","*   Deploy it (Optional)\n","*   Begin your presentation (2h)\n","*   Presentation (5 min/groups)\n","\n","\n","We'll evaluate your presentation quality, your RAG system's capability, and your progress throughout the project sessions.\n","\n","**Students who missed the first session will start with a score of 0 in the progress part**. :-)\n"]},{"cell_type":"markdown","metadata":{"id":"Jd-X5ehunElN"},"source":["Presentation:\n","- The number of slides you can do is unlimited\n","- You only have 5 min to present your project. We will stop you at 5 min whether you've finished or not\n","- Your presentation should include:\n","  - a presentation of your workflow (Agile Methodology, What's the job of each one...)\n","  - a presentation of your final pipeline with all enhancements done\n","  - a proof a work of your RAG on your data, and on the unknown data\n","  - what limitations you have and how to tackle them. For each too obvious limitations (more GPUs, more RAM..) : -1\n","  - if you've deployed your RAG, a scannable QR code to live test it."]},{"cell_type":"markdown","metadata":{"id":"53l6aIRMhsJL"},"source":["#  Preliminaries : Some useful downloads\n","\n","We give you some useful frameworks, that you could use to build your RAG."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-03-24T14:14:35.280411Z","iopub.status.busy":"2024-03-24T14:14:35.279581Z","iopub.status.idle":"2024-03-24T14:16:05.671778Z","shell.execute_reply":"2024-03-24T14:16:05.670600Z","shell.execute_reply.started":"2024-03-24T14:14:35.280376Z"},"id":"pty32z_YuW_f","outputId":"7db65b17-6057-44a3-b7d8-dc3d3bc69ab5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.4)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.10/site-packages (2.6.0)\n","Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.38.2)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\n","Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.1.2)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.21.4)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.3.0)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n","Requirement already satisfied: llama-index in /opt/conda/lib/python3.10/site-packages (0.10.23)\n","Requirement already satisfied: llama-index-agent-openai<0.2.0,>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.7)\n","Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.11)\n","Requirement already satisfied: llama-index-core<0.11.0,>=0.10.23 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.10.23.post1)\n","Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.7)\n","Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.5)\n","Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.9.48)\n","Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.12)\n","Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.4)\n","Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.4)\n","Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.3)\n","Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.12)\n","Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index) (0.1.3)\n","Requirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (6.0.1)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.23->llama-index) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (3.9.1)\n","Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.6.4)\n","Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.2.14)\n","Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.0.8)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (2024.3.0)\n","Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.27.0)\n","Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.1.13)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.5.8)\n","Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (3.2.1)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (3.8.1)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.26.4)\n","Requirement already satisfied: openai>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.14.2)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (2.1.4)\n","Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (9.5.0)\n","Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (8.2.3)\n","Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.6.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (4.66.1)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (4.9.0)\n","Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.9.0)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n","Requirement already satisfied: bs4<0.0.3,>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.2)\n","Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.0)\n","Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n","Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n","Requirement already satisfied: llama-parse<0.4.0,>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.3.9)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.23->llama-index) (4.0.3)\n","Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n","Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.14.1)\n","Requirement already satisfied: pydantic>=1.10 in /opt/conda/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.23->llama-index) (2.5.3)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (4.2.0)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.0.4)\n","Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (3.6)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (0.14.0)\n","Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.23->llama-index) (8.1.7)\n","Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.3.2)\n","Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.23->llama-index) (2023.12.25)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.9.0)\n","Requirement already satisfied: PyMuPDFb==1.24.0 in /opt/conda/lib/python3.10/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.23->llama-index) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.26.18)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.23->llama-index) (3.0.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.0.0)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.23->llama-index) (3.21.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (2023.4)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.2.0)\n","Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.23->llama-index) (23.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.23->llama-index) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.23->llama-index) (2.14.6)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.16.0)\n","Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n"]}],"source":["!pip install -q pypdf python-dotenv\n","!pip install transformers\n","!pip install -q datasets loralib sentencepiece\n","!pip install -q einops accelerate langchain bitsandbytes\n","!pip install sentence_transformers\n","!pip install llama-index\n","# !%pip install --upgrade --quiet  langchain langchain-openai faiss-cpu tiktoken\n","!pip install faiss-gpu"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:17:36.834556Z","iopub.status.busy":"2024-03-24T14:17:36.833715Z","iopub.status.idle":"2024-03-24T14:17:36.839807Z","shell.execute_reply":"2024-03-24T14:17:36.838871Z","shell.execute_reply.started":"2024-03-24T14:17:36.834523Z"},"trusted":true},"outputs":[],"source":["from langchain.document_loaders import HuggingFaceDatasetLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.vectorstores import FAISS\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n","from transformers import AutoTokenizer, pipeline\n","from langchain import HuggingFacePipeline\n","from langchain.chains import RetrievalQA"]},{"cell_type":"markdown","metadata":{"id":"NmBmFi1LzltU"},"source":["# I - Data Sourcing\n","\n","Data Sourcing for RAG is really simple. Some questions to guide you:\n","\n","* What data do we need ?\n","* How can we correctly parse the data ?\n","* Does the vector index provides a good representation for the vector database ?\n","* For example, using FAISS, can you easily retrieve your document ?\n","\n","To begin, pick a simple story and store it in a Vector Database. You have the choice between multiple VectorStores (ChromaDB, QDrant,...)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:17:37.324405Z","iopub.status.busy":"2024-03-24T14:17:37.324049Z","iopub.status.idle":"2024-03-24T14:17:37.331861Z","shell.execute_reply":"2024-03-24T14:17:37.330967Z","shell.execute_reply.started":"2024-03-24T14:17:37.324377Z"},"id":"bJkSurPXlPd9","trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.document_loaders import PyPDFDirectoryLoader\n","\n","loader = PyPDFDirectoryLoader(\"/kaggle/input/rag-test/\")\n","data = loader.load()\n","len(data)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:17:37.767065Z","iopub.status.busy":"2024-03-24T14:17:37.766718Z","iopub.status.idle":"2024-03-24T14:17:37.771754Z","shell.execute_reply":"2024-03-24T14:17:37.770840Z","shell.execute_reply.started":"2024-03-24T14:17:37.767036Z"},"trusted":true},"outputs":[],"source":["# Create an instance of the RecursiveCharacterTextSplitter class with specific parameters.\n","# It splits text into chunks of 1000 characters each with a 150-character overlap.\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n","\n","# 'data' holds the text you want to split, split the text into documents using the text splitter.\n","docs = text_splitter.split_documents(data)"]},{"cell_type":"markdown","metadata":{"id":"JPNynNQm0z4N"},"source":["# II - Module Creation\n","\n","Should you create a RAG Module, you need or not a LLM. We encourage you to test some LLMs (Mistral, LLama, Falcon, Gemma, ...) However, be aware that you won't have the space to run it on this colab.\n","\n","We highly recommend to use LangChain, to build your Q&A app.\n","\n","Some Questions to guide you:\n","* What model is easily accesible\n","* Are there any existing code to begin with ?\n","* What about the prompts ?\n","* What about the document parsing ?\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:17:38.805550Z","iopub.status.busy":"2024-03-24T14:17:38.805140Z","iopub.status.idle":"2024-03-24T14:17:40.619543Z","shell.execute_reply":"2024-03-24T14:17:40.618734Z","shell.execute_reply.started":"2024-03-24T14:17:38.805521Z"},"id":"cmsXxSw3mJuS","trusted":true},"outputs":[],"source":["# Define the path to the pre-trained model you want to use\n","modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n","modelPath='BAAI/bge-large-zh-v1.5'\n","\n","# Create a dictionary with model configuration options, specifying to use the CPU for computations\n","model_kwargs = {'device':'cpu'}\n","\n","# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n","encode_kwargs = {'normalize_embeddings': False}\n","\n","# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n","embeddings = HuggingFaceEmbeddings(\n","    model_name=modelPath,     # Provide the pre-trained model's path\n","    model_kwargs=model_kwargs, # Pass the model configuration options\n","    encode_kwargs=encode_kwargs # Pass the encoding options\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-03-24T14:17:40.621169Z","iopub.status.busy":"2024-03-24T14:17:40.620911Z","iopub.status.idle":"2024-03-24T14:17:40.759227Z","shell.execute_reply":"2024-03-24T14:17:40.758054Z","shell.execute_reply.started":"2024-03-24T14:17:40.621147Z"},"trusted":true},"outputs":[{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_core/vectorstores.py:528\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m texts \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    527\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [d\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:931\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03mThis is a user friendly interface that:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;124;03m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    930\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m--> 931\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:888\u001b[0m, in \u001b[0;36mFAISS.__from\u001b[0;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m     index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatIP(\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;66;03m# Default to L2, currently other metric types not initialized.\u001b[39;00m\n\u001b[0;32m--> 888\u001b[0m     index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatL2(\u001b[38;5;28mlen\u001b[39m(\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m    889\u001b[0m docstore \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocstore\u001b[39m\u001b[38;5;124m\"\u001b[39m, InMemoryDocstore())\n\u001b[1;32m    890\u001b[0m index_to_docstore_id \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex_to_docstore_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}],"source":["db = FAISS.from_documents(docs, embeddings)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:11:22.432034Z","iopub.status.idle":"2024-03-24T14:11:22.432546Z","shell.execute_reply":"2024-03-24T14:11:22.432324Z","shell.execute_reply.started":"2024-03-24T14:11:22.432303Z"},"trusted":true},"outputs":[],"source":["question = \"What is cheesemaking?\"\n","searchDocs = db.similarity_search(question)\n","print(searchDocs[0].page_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:11:22.434042Z","iopub.status.idle":"2024-03-24T14:11:22.434515Z","shell.execute_reply":"2024-03-24T14:11:22.434303Z","shell.execute_reply.started":"2024-03-24T14:11:22.434284Z"},"trusted":true},"outputs":[],"source":["# # Create a tokenizer object by loading the pretrained \"Intel/dynamic_tinybert\" tokenizer.\n","# tokenizer = AutoTokenizer.from_pretrained(\"Intel/dynamic_tinybert\")\n","\n","# # Create a question-answering model object by loading the pretrained \"Intel/dynamic_tinybert\" model.\n","# model = AutoModelForQuestionAnswering.from_pretrained(\"Intel/dynamic_tinybert\")"]},{"cell_type":"markdown","metadata":{},"source":["## Models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:11:22.435883Z","iopub.status.idle":"2024-03-24T14:11:22.436347Z","shell.execute_reply":"2024-03-24T14:11:22.436120Z","shell.execute_reply.started":"2024-03-24T14:11:22.436101Z"},"trusted":true},"outputs":[],"source":["from torch import bfloat16\n","import transformers\n","\n","model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n","\n","model = transformers.AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    trust_remote_code=True,\n","    torch_dtype=bfloat16,\n","    device_map='auto',\n","    \n",")\n","model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:11:22.438148Z","iopub.status.idle":"2024-03-24T14:11:22.438508Z","shell.execute_reply":"2024-03-24T14:11:22.438353Z","shell.execute_reply.started":"2024-03-24T14:11:22.438339Z"},"trusted":true},"outputs":[],"source":["tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:11:22.439915Z","iopub.status.idle":"2024-03-24T14:11:22.440263Z","shell.execute_reply":"2024-03-24T14:11:22.440096Z","shell.execute_reply.started":"2024-03-24T14:11:22.440082Z"},"trusted":true},"outputs":[],"source":["pip = pipeline(\n","    model=model, tokenizer=tokenizer,\n","    return_full_text=False,  # if using langchain set True\n","    task=\"text-generation\",\n","    # we pass model parameters here too\n","    temperature=0.1,  # 'randomness' of outputs, 0.0 is the min and 1.0 the max\n","    top_p=0.15,  # select from top tokens whose probability add up to 15%\n","    top_k=0,  # select from top 0 tokens (because zero, relies on top_p)\n","    max_new_tokens=512,  # max number of tokens to generate in the output\n","    repetition_penalty=1.1,  # if output begins repeating increase\n","    do_sample=True,\n",")\n","llm = HuggingFacePipeline(\n","    pipeline=pip,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:11:22.442269Z","iopub.status.idle":"2024-03-24T14:11:22.442612Z","shell.execute_reply":"2024-03-24T14:11:22.442466Z","shell.execute_reply.started":"2024-03-24T14:11:22.442452Z"},"trusted":true},"outputs":[],"source":["llm.invoke(\"What is cheesemaking?\")"]},{"cell_type":"markdown","metadata":{},"source":["## Retrivers"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:11:22.444064Z","iopub.status.idle":"2024-03-24T14:11:22.444423Z","shell.execute_reply":"2024-03-24T14:11:22.444269Z","shell.execute_reply.started":"2024-03-24T14:11:22.444252Z"},"trusted":true},"outputs":[],"source":["# Create a retriever object from the 'db' using the 'as_retriever' method.\n","# This retriever is likely used for retrieving data or documents from the database.\n","retriever = db.as_retriever()\n","\n","docs = retriever.get_relevant_documents(\"What is Cheesemaking?\")\n","print(docs[0].page_content) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:11:22.445431Z","iopub.status.idle":"2024-03-24T14:11:22.445735Z","shell.execute_reply":"2024-03-24T14:11:22.445596Z","shell.execute_reply.started":"2024-03-24T14:11:22.445583Z"},"trusted":true},"outputs":[],"source":["\n","\n","# Create a retriever object from the 'db' with a search configuration where it retrieves up to 4 relevant splits/documents.\n","retriever = db.as_retriever(search_kwargs={\"k\": 4})\n","\n","# Create a question-answering instance (qa) using the RetrievalQA class.\n","# It's configured with a language model (llm), a chain type \"refine,\" the retriever we created, and an option to not return source documents. \n","qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"refine\", retriever=retriever, return_source_documents=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-24T14:11:22.447089Z","iopub.status.idle":"2024-03-24T14:11:22.447528Z","shell.execute_reply":"2024-03-24T14:11:22.447325Z","shell.execute_reply.started":"2024-03-24T14:11:22.447307Z"},"trusted":true},"outputs":[],"source":["question = \"Who is Laura?\"\n","result = qa.invoke({\"query\": question})\n","print(result)"]},{"cell_type":"markdown","metadata":{"id":"JeMHYQwc02uG"},"source":["# III - Model Serving (Optional and for the best)\n","\n","You can inspire yourself from the first hands-on, if your feeling powerful, you can build something using fastapi and push your deployed RAG into a simple github.io instance. Or just use the gradio deploiement framework."]}],"metadata":{"colab":{"include_colab_link":true,"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4661311,"sourceId":7930425,"sourceType":"datasetVersion"},{"sourceId":167593074,"sourceType":"kernelVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
